{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded_scaled = pd.read_csv('data/data_encoded_scaled.csv')\n",
    "data_cleaned = pd.read_csv('data/data_cleaned.csv')\n",
    "data_feature = data_cleaned.drop(columns=['TOTAL_DELAY', 'DEP_DEL15'])\n",
    "data_target = data_cleaned['DEP_DEL15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded_scaled = data_encoded_scaled.drop(columns=['DEP_DEL15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.968432919954903\n"
     ]
    }
   ],
   "source": [
    "sequence_days = 7\n",
    "daily_counts = data_feature.groupby(['MONTH', 'DAY_OF_MONTH', 'DEPARTING_AIRPORT']).size()\n",
    "average_rows = daily_counts.mean()\n",
    "\n",
    "print(average_rows*sequence_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_encoded_scaled.assign(TARGET=data_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK  DEP_TIME_BLK  DISTANCE_GROUP  \\\n",
      "0    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "1    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "2    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "3    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "4    0.0           0.0     0.166667      0.166667        0.285714   \n",
      "\n",
      "   SEGMENT_NUMBER  CONCURRENT_FLIGHTS  NUMBER_OF_SEATS  AIRPORT_FLIGHTS_MONTH  \\\n",
      "0           0.000            0.098592              1.0               0.115453   \n",
      "1           0.000            0.098592              1.0               0.115453   \n",
      "2           0.000            0.112676              1.0               0.111384   \n",
      "3           0.000            0.267606              1.0               0.333661   \n",
      "4           0.125            0.042254              1.0               0.028528   \n",
      "\n",
      "   AIRLINE_FLIGHTS_MONTH  ...  PREVIOUS_AIRPORT_4  PREVIOUS_AIRPORT_5  \\\n",
      "0               0.183515  ...                 0.0                 0.0   \n",
      "1               0.183515  ...                 0.0                 0.0   \n",
      "2               0.183515  ...                 0.0                 0.0   \n",
      "3               0.183515  ...                 0.0                 0.0   \n",
      "4               0.183515  ...                 0.0                 1.0   \n",
      "\n",
      "   PREVIOUS_AIRPORT_6  PRCP  SNOW  SNWD      TMAX      AWND  RESIDUALS  TARGET  \n",
      "0                 1.0   0.0   0.0   0.0  0.353982  0.198638   0.052138       0  \n",
      "1                 1.0   0.0   0.0   0.0  0.353982  0.198638   0.052775       0  \n",
      "2                 1.0   0.0   0.0   0.0  0.451327  0.172291   0.051816       0  \n",
      "3                 1.0   0.0   0.0   0.0  0.699115  0.370930   0.051928       0  \n",
      "4                 0.0   0.0   0.0   0.0  0.460177  0.178804   0.051987       0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: (41100, 28, 33)\n",
      "Target values shape: (41100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequence_length = int(round(average_rows*sequence_days))\n",
    "\n",
    "unique_dep_airport = data_feature['DEPARTING_AIRPORT'].unique()\n",
    "unique_flight_number = data_feature['FLIGHT_NUMBER'].unique()\n",
    "\n",
    "X_sequences = []\n",
    "y_targets = []\n",
    "\n",
    "for dep_airport in unique_dep_airport:\n",
    "    flight_data = data_full[data_feature['DEPARTING_AIRPORT'] == dep_airport]\n",
    "    flight_data_values = flight_data.iloc[:, :-1].values\n",
    "    flight_data_target = flight_data.iloc[:, -1].values\n",
    "    for i in range(len(flight_data) - sequence_length):\n",
    "        X_sequences.append(flight_data_values[i:i+sequence_length])\n",
    "        y_targets.append(flight_data_target[i+sequence_length])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_targets = np.array(y_targets)\n",
    "\n",
    "print(\"Input sequences shape:\", X_sequences.shape)\n",
    "print(\"Target values shape:\", y_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = list(zip(X_sequences, y_targets))\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Separate the sequences and targets\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "# Convert the results back to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Semester 3\\Deep Learning\\flight_delay\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "from tensorflow.compat.v1.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "timesteps = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(y_train) , y = y_train)\n",
    "class_weights = dict(zip(np.unique(y_train), weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Semester 3\\Deep Learning\\flight_delay\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/300\n",
      "WARNING:tensorflow:From e:\\Semester 3\\Deep Learning\\flight_delay\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\Semester 3\\Deep Learning\\flight_delay\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "816/822 [============================>.] - ETA: 0s - loss: 1.2167 - accuracy: 0.4699 - recall: 0.6042\n",
      "Epoch 1: val_loss improved from inf to 0.97074, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 7s 7ms/step - loss: 1.2153 - accuracy: 0.4711 - recall: 0.6025 - val_loss: 0.9707 - val_accuracy: 0.6613 - val_recall: 0.3699\n",
      "Epoch 2/300\n",
      " 19/822 [..............................] - ETA: 4s - loss: 1.0479 - accuracy: 0.5954 - recall: 0.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Semester 3\\Deep Learning\\flight_delay\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/822 [============================>.] - ETA: 0s - loss: 0.8999 - accuracy: 0.5438 - recall: 0.5644\n",
      "Epoch 2: val_loss improved from 0.97074 to 0.81017, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.8991 - accuracy: 0.5443 - recall: 0.5643 - val_loss: 0.8102 - val_accuracy: 0.5858 - val_recall: 0.5705\n",
      "Epoch 3/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.7839 - accuracy: 0.5411 - recall: 0.5843\n",
      "Epoch 3: val_loss improved from 0.81017 to 0.76063, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7838 - accuracy: 0.5408 - recall: 0.5843 - val_loss: 0.7606 - val_accuracy: 0.5220 - val_recall: 0.6801\n",
      "Epoch 4/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.7399 - accuracy: 0.5404 - recall: 0.5869\n",
      "Epoch 4: val_loss improved from 0.76063 to 0.73710, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7405 - accuracy: 0.5398 - recall: 0.5872 - val_loss: 0.7371 - val_accuracy: 0.5144 - val_recall: 0.6930\n",
      "Epoch 5/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.7211 - accuracy: 0.5333 - recall: 0.6164\n",
      "Epoch 5: val_loss improved from 0.73710 to 0.71012, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7211 - accuracy: 0.5333 - recall: 0.6164 - val_loss: 0.7101 - val_accuracy: 0.5655 - val_recall: 0.6309\n",
      "Epoch 6/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.7118 - accuracy: 0.5395 - recall: 0.5943\n",
      "Epoch 6: val_loss improved from 0.71012 to 0.70083, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7116 - accuracy: 0.5395 - recall: 0.5940 - val_loss: 0.7008 - val_accuracy: 0.5703 - val_recall: 0.6237\n",
      "Epoch 7/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.5429 - recall: 0.6089\n",
      "Epoch 7: val_loss did not improve from 0.70083\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7051 - accuracy: 0.5430 - recall: 0.6090 - val_loss: 0.7124 - val_accuracy: 0.5138 - val_recall: 0.6922\n",
      "Epoch 8/300\n",
      "818/822 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.5355 - recall: 0.6142\n",
      "Epoch 8: val_loss improved from 0.70083 to 0.69301, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.7011 - accuracy: 0.5355 - recall: 0.6142 - val_loss: 0.6930 - val_accuracy: 0.5666 - val_recall: 0.6245\n",
      "Epoch 9/300\n",
      "817/822 [============================>.] - ETA: 0s - loss: 0.6965 - accuracy: 0.5483 - recall: 0.6080\n",
      "Epoch 9: val_loss did not improve from 0.69301\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6962 - accuracy: 0.5481 - recall: 0.6084 - val_loss: 0.7028 - val_accuracy: 0.5309 - val_recall: 0.6737\n",
      "Epoch 10/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5412 - recall: 0.6147\n",
      "Epoch 10: val_loss improved from 0.69301 to 0.68130, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6942 - accuracy: 0.5419 - recall: 0.6154 - val_loss: 0.6813 - val_accuracy: 0.5923 - val_recall: 0.5898\n",
      "Epoch 11/300\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5401 - recall: 0.6097\n",
      "Epoch 11: val_loss improved from 0.68130 to 0.67379, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6925 - accuracy: 0.5404 - recall: 0.6094 - val_loss: 0.6738 - val_accuracy: 0.6069 - val_recall: 0.5633\n",
      "Epoch 12/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5389 - recall: 0.6053\n",
      "Epoch 12: val_loss did not improve from 0.67379\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6910 - accuracy: 0.5390 - recall: 0.6049 - val_loss: 0.6777 - val_accuracy: 0.5849 - val_recall: 0.6003\n",
      "Epoch 13/300\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.6896 - accuracy: 0.5412 - recall: 0.6093\n",
      "Epoch 13: val_loss improved from 0.67379 to 0.67308, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6897 - accuracy: 0.5413 - recall: 0.6092 - val_loss: 0.6731 - val_accuracy: 0.5970 - val_recall: 0.5794\n",
      "Epoch 14/300\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.6877 - accuracy: 0.5398 - recall: 0.6115\n",
      "Epoch 14: val_loss improved from 0.67308 to 0.67068, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 7ms/step - loss: 0.6881 - accuracy: 0.5405 - recall: 0.6108 - val_loss: 0.6707 - val_accuracy: 0.6033 - val_recall: 0.5770\n",
      "Epoch 15/300\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.5508 - recall: 0.5876\n",
      "Epoch 15: val_loss did not improve from 0.67068\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6874 - accuracy: 0.5501 - recall: 0.5890 - val_loss: 0.7142 - val_accuracy: 0.4668 - val_recall: 0.7583\n",
      "Epoch 16/300\n",
      "818/822 [============================>.] - ETA: 0s - loss: 0.6871 - accuracy: 0.5341 - recall: 0.6254\n",
      "Epoch 16: val_loss did not improve from 0.67068\n",
      "822/822 [==============================] - 7s 9ms/step - loss: 0.6867 - accuracy: 0.5344 - recall: 0.6255 - val_loss: 0.6814 - val_accuracy: 0.5648 - val_recall: 0.6221\n",
      "Epoch 17/300\n",
      "817/822 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.5391 - recall: 0.6006\n",
      "Epoch 17: val_loss did not improve from 0.67068\n",
      "822/822 [==============================] - 7s 8ms/step - loss: 0.6859 - accuracy: 0.5392 - recall: 0.6013 - val_loss: 0.6721 - val_accuracy: 0.5887 - val_recall: 0.5939\n",
      "Epoch 18/300\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.5500 - recall: 0.5956\n",
      "Epoch 18: val_loss did not improve from 0.67068\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6854 - accuracy: 0.5496 - recall: 0.5958 - val_loss: 0.6877 - val_accuracy: 0.5397 - val_recall: 0.6535\n",
      "Epoch 19/300\n",
      "813/822 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.5456 - recall: 0.6050\n",
      "Epoch 19: val_loss did not improve from 0.67068\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6856 - accuracy: 0.5446 - recall: 0.6047 - val_loss: 0.6965 - val_accuracy: 0.5108 - val_recall: 0.6946\n",
      "Epoch 20/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.5434 - recall: 0.6104\n",
      "Epoch 20: val_loss improved from 0.67068 to 0.65687, saving model to model\\best_model_hybrid_GRUs.h5\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6839 - accuracy: 0.5437 - recall: 0.6102 - val_loss: 0.6569 - val_accuracy: 0.6297 - val_recall: 0.5157\n",
      "Epoch 21/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.5482 - recall: 0.5902\n",
      "Epoch 21: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6850 - accuracy: 0.5482 - recall: 0.5900 - val_loss: 0.6815 - val_accuracy: 0.5573 - val_recall: 0.6334\n",
      "Epoch 22/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.5436 - recall: 0.5983\n",
      "Epoch 22: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6840 - accuracy: 0.5431 - recall: 0.5981 - val_loss: 0.6791 - val_accuracy: 0.5637 - val_recall: 0.6253\n",
      "Epoch 23/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.6830 - accuracy: 0.5448 - recall: 0.6056\n",
      "Epoch 23: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6835 - accuracy: 0.5446 - recall: 0.6049 - val_loss: 0.6848 - val_accuracy: 0.5449 - val_recall: 0.6551\n",
      "Epoch 24/300\n",
      "817/822 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.5391 - recall: 0.6054\n",
      "Epoch 24: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6837 - accuracy: 0.5384 - recall: 0.6045 - val_loss: 0.6833 - val_accuracy: 0.5494 - val_recall: 0.6446\n",
      "Epoch 25/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6822 - accuracy: 0.5456 - recall: 0.6070\n",
      "Epoch 25: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6821 - accuracy: 0.5458 - recall: 0.6067 - val_loss: 0.6778 - val_accuracy: 0.5675 - val_recall: 0.6237\n",
      "Epoch 26/300\n",
      "813/822 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5472 - recall: 0.5954\n",
      "Epoch 26: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6831 - accuracy: 0.5462 - recall: 0.5954 - val_loss: 0.6985 - val_accuracy: 0.5030 - val_recall: 0.7115\n",
      "Epoch 27/300\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5409 - recall: 0.6092\n",
      "Epoch 27: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6825 - accuracy: 0.5407 - recall: 0.6092 - val_loss: 0.6859 - val_accuracy: 0.5371 - val_recall: 0.6583\n",
      "Epoch 28/300\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.5400 - recall: 0.6112\n",
      "Epoch 28: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6818 - accuracy: 0.5402 - recall: 0.6108 - val_loss: 0.6678 - val_accuracy: 0.5931 - val_recall: 0.5858\n",
      "Epoch 29/300\n",
      "818/822 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.5445 - recall: 0.5970\n",
      "Epoch 29: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6812 - accuracy: 0.5443 - recall: 0.5964 - val_loss: 0.6739 - val_accuracy: 0.5754 - val_recall: 0.6124\n",
      "Epoch 30/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.5437 - recall: 0.6038\n",
      "Epoch 30: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6813 - accuracy: 0.5439 - recall: 0.6035 - val_loss: 0.6671 - val_accuracy: 0.5952 - val_recall: 0.5826\n",
      "Epoch 31/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6819 - accuracy: 0.5513 - recall: 0.5897\n",
      "Epoch 31: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 7ms/step - loss: 0.6820 - accuracy: 0.5513 - recall: 0.5894 - val_loss: 0.6827 - val_accuracy: 0.5449 - val_recall: 0.6438\n",
      "Epoch 32/300\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.6822 - accuracy: 0.5387 - recall: 0.6057\n",
      "Epoch 32: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6825 - accuracy: 0.5381 - recall: 0.6051 - val_loss: 0.6783 - val_accuracy: 0.5550 - val_recall: 0.6269\n",
      "Epoch 33/300\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5402 - recall: 0.6072\n",
      "Epoch 33: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6813 - accuracy: 0.5401 - recall: 0.6072 - val_loss: 0.6789 - val_accuracy: 0.5541 - val_recall: 0.6366\n",
      "Epoch 34/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.5440 - recall: 0.6034\n",
      "Epoch 34: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6810 - accuracy: 0.5441 - recall: 0.6041 - val_loss: 0.6791 - val_accuracy: 0.5610 - val_recall: 0.6317\n",
      "Epoch 35/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6815 - accuracy: 0.5505 - recall: 0.5942\n",
      "Epoch 35: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6816 - accuracy: 0.5504 - recall: 0.5942 - val_loss: 0.6976 - val_accuracy: 0.4986 - val_recall: 0.7115\n",
      "Epoch 36/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6824 - accuracy: 0.5351 - recall: 0.6088\n",
      "Epoch 36: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6824 - accuracy: 0.5353 - recall: 0.6086 - val_loss: 0.6658 - val_accuracy: 0.5949 - val_recall: 0.5866\n",
      "Epoch 37/300\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.5472 - recall: 0.5950\n",
      "Epoch 37: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6815 - accuracy: 0.5464 - recall: 0.5950 - val_loss: 0.6877 - val_accuracy: 0.5303 - val_recall: 0.6817\n",
      "Epoch 38/300\n",
      "814/822 [============================>.] - ETA: 0s - loss: 0.6824 - accuracy: 0.5388 - recall: 0.6015\n",
      "Epoch 38: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6819 - accuracy: 0.5387 - recall: 0.6019 - val_loss: 0.6855 - val_accuracy: 0.5350 - val_recall: 0.6688\n",
      "Epoch 39/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.5438 - recall: 0.6038\n",
      "Epoch 39: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6810 - accuracy: 0.5436 - recall: 0.6041 - val_loss: 0.6898 - val_accuracy: 0.5225 - val_recall: 0.6817\n",
      "Epoch 40/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6816 - accuracy: 0.5415 - recall: 0.6058\n",
      "Epoch 40: val_loss did not improve from 0.65687\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.6813 - accuracy: 0.5416 - recall: 0.6055 - val_loss: 0.6852 - val_accuracy: 0.5353 - val_recall: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2210813a2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(32, input_shape=(timesteps, input_dim),\n",
    "                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                    recurrent_regularizer=regularizers.l2(0.01),\n",
    "                    bias_regularizer=regularizers.l2(0.01),\n",
    "                     dropout=0.4, recurrent_dropout=0.4))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', Recall()])\n",
    "\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model/best_model_hybrid_GRUs.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_split=0.2, callbacks=[early_stopping, checkpoint], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 1s 2ms/step\n",
      "      Prediction  Actual\n",
      "0       0.312500       0\n",
      "1       0.521785       0\n",
      "2       0.566728       0\n",
      "3       0.310020       0\n",
      "4       0.523246       0\n",
      "...          ...     ...\n",
      "8215    0.524940       0\n",
      "8216    0.532093       1\n",
      "8217    0.498396       0\n",
      "8218    0.490252       0\n",
      "8219    0.497601       0\n",
      "\n",
      "[8220 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the model\n",
    "best_model = load_model('model/best_model_hybrid_GRUs.h5')\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Compare the predictions with the actual values\n",
    "comparison = pd.DataFrame({'Prediction': predictions.flatten(), 'Actual': y_test})\n",
    "\n",
    "# Print the comparison\n",
    "print(comparison)\n",
    "predictions_labels = [1 if p > 0.5 else 0 for p in predictions.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_labels)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73      6693\n",
      "           1       0.25      0.53      0.34      1527\n",
      "\n",
      "    accuracy                           0.62      8220\n",
      "   macro avg       0.55      0.58      0.54      8220\n",
      "weighted avg       0.74      0.62      0.66      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions_labels, output_dict=True)\n",
    "print(classification_report(y_test, predictions_labels))\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv('result/hybrid_GRUs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
