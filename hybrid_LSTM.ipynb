{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42c38f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a63ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded_scaled = pd.read_csv('data/data_encoded_scaled.csv')\n",
    "data_cleaned = pd.read_csv('data/data_cleaned.csv')\n",
    "data_feature = data_cleaned.drop(columns=['TOTAL_DELAY', 'DEP_DEL15'])\n",
    "data_target = data_cleaned['DEP_DEL15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd8c93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded_scaled = data_encoded_scaled.drop(columns=['DEP_DEL15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "887cb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.968432919954903\n"
     ]
    }
   ],
   "source": [
    "sequence_days = 7\n",
    "daily_counts = data_feature.groupby(['MONTH', 'DAY_OF_MONTH', 'DEPARTING_AIRPORT']).size() # 一天一个机场的航班数\n",
    "average_rows = daily_counts.mean()\n",
    "\n",
    "print(average_rows*sequence_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48a73f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_encoded_scaled.assign(TARGET=data_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17149eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK  DEP_TIME_BLK  DISTANCE_GROUP  \\\n",
      "0    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "1    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "2    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "3    0.0           0.0     0.166667      0.166667        0.428571   \n",
      "4    0.0           0.0     0.166667      0.166667        0.285714   \n",
      "\n",
      "   SEGMENT_NUMBER  CONCURRENT_FLIGHTS  NUMBER_OF_SEATS  AIRPORT_FLIGHTS_MONTH  \\\n",
      "0           0.000            0.098592              1.0               0.115453   \n",
      "1           0.000            0.098592              1.0               0.115453   \n",
      "2           0.000            0.112676              1.0               0.111384   \n",
      "3           0.000            0.267606              1.0               0.333661   \n",
      "4           0.125            0.042254              1.0               0.028528   \n",
      "\n",
      "   AIRLINE_FLIGHTS_MONTH  ...  PREVIOUS_AIRPORT_4  PREVIOUS_AIRPORT_5  \\\n",
      "0               0.183515  ...                 0.0                 0.0   \n",
      "1               0.183515  ...                 0.0                 0.0   \n",
      "2               0.183515  ...                 0.0                 0.0   \n",
      "3               0.183515  ...                 0.0                 0.0   \n",
      "4               0.183515  ...                 0.0                 1.0   \n",
      "\n",
      "   PREVIOUS_AIRPORT_6  PRCP  SNOW  SNWD      TMAX      AWND  RESIDUALS  TARGET  \n",
      "0                 1.0   0.0   0.0   0.0  0.353982  0.198638   0.052138       0  \n",
      "1                 1.0   0.0   0.0   0.0  0.353982  0.198638   0.052775       0  \n",
      "2                 1.0   0.0   0.0   0.0  0.451327  0.172291   0.051816       0  \n",
      "3                 1.0   0.0   0.0   0.0  0.699115  0.370930   0.051928       0  \n",
      "4                 0.0   0.0   0.0   0.0  0.460177  0.178804   0.051987       0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e048c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: (41100, 28, 33)\n",
      "Target values shape: (41100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequence_length = int(round(average_rows*sequence_days))\n",
    "\n",
    "unique_dep_airport = data_feature['DEPARTING_AIRPORT'].unique()\n",
    "unique_flight_number = data_feature['FLIGHT_NUMBER'].unique()\n",
    "\n",
    "X_sequences = []\n",
    "y_targets = []\n",
    "\n",
    "for dep_airport in unique_dep_airport:\n",
    "    flight_data = data_full[data_feature['DEPARTING_AIRPORT'] == dep_airport]\n",
    "    flight_data_values = flight_data.iloc[:, :-1].values\n",
    "    flight_data_target = flight_data.iloc[:, -1].values\n",
    "    for i in range(len(flight_data) - sequence_length):\n",
    "        X_sequences.append(flight_data_values[i:i+sequence_length])\n",
    "        y_targets.append(flight_data_target[i+sequence_length])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_targets = np.array(y_targets)\n",
    "\n",
    "print(\"Input sequences shape:\", X_sequences.shape)\n",
    "print(\"Target values shape:\", y_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4e5c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = list(zip(X_sequences, y_targets))\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Separate the sequences and targets\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "# Convert the results back to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "719e17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "from tensorflow.compat.v1.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "timesteps = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(y_train) , y = y_train)\n",
    "class_weights = dict(zip(np.unique(y_train), weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28047b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.5364 - recall_1: 0.5297\n",
      "Epoch 1: val_loss improved from inf to 1.25921, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 15s 15ms/step - loss: 1.5141 - accuracy: 0.5366 - recall_1: 0.5300 - val_loss: 1.2592 - val_accuracy: 0.5228 - val_recall_1: 0.5847\n",
      "Epoch 2/300\n",
      "  7/822 [..............................] - ETA: 15s - loss: 1.2964 - accuracy: 0.5312 - recall_1: 0.5417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaozhangyu/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821/822 [============================>.] - ETA: 0s - loss: 1.1275 - accuracy: 0.5258 - recall_1: 0.6050\n",
      "Epoch 2: val_loss improved from 1.25921 to 1.02041, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 1.1273 - accuracy: 0.5257 - recall_1: 0.6048 - val_loss: 1.0204 - val_accuracy: 0.5405 - val_recall_1: 0.5855\n",
      "Epoch 3/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.9717 - accuracy: 0.5341 - recall_1: 0.6171\n",
      "Epoch 3: val_loss improved from 1.02041 to 0.93209, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.9721 - accuracy: 0.5342 - recall_1: 0.6169 - val_loss: 0.9321 - val_accuracy: 0.5046 - val_recall_1: 0.6629\n",
      "Epoch 4/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.8963 - accuracy: 0.5310 - recall_1: 0.6337\n",
      "Epoch 4: val_loss improved from 0.93209 to 0.86780, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.8963 - accuracy: 0.5310 - recall_1: 0.6337 - val_loss: 0.8678 - val_accuracy: 0.5436 - val_recall_1: 0.6173\n",
      "Epoch 5/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.8490 - accuracy: 0.5417 - recall_1: 0.6162\n",
      "Epoch 5: val_loss improved from 0.86780 to 0.84048, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.8492 - accuracy: 0.5416 - recall_1: 0.6157 - val_loss: 0.8405 - val_accuracy: 0.5023 - val_recall_1: 0.6832\n",
      "Epoch 6/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.8128 - accuracy: 0.5377 - recall_1: 0.6276\n",
      "Epoch 6: val_loss improved from 0.84048 to 0.79477, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.8130 - accuracy: 0.5378 - recall_1: 0.6276 - val_loss: 0.7948 - val_accuracy: 0.5485 - val_recall_1: 0.6205\n",
      "Epoch 7/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.7833 - accuracy: 0.5356 - recall_1: 0.6299\n",
      "Epoch 7: val_loss improved from 0.79477 to 0.75936, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.7832 - accuracy: 0.5356 - recall_1: 0.6292 - val_loss: 0.7594 - val_accuracy: 0.5687 - val_recall_1: 0.5814\n",
      "Epoch 8/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.7593 - accuracy: 0.5383 - recall_1: 0.6245\n",
      "Epoch 8: val_loss improved from 0.75936 to 0.75449, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 13s 15ms/step - loss: 0.7592 - accuracy: 0.5385 - recall_1: 0.6248 - val_loss: 0.7545 - val_accuracy: 0.5213 - val_recall_1: 0.6572\n",
      "Epoch 9/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.7384 - accuracy: 0.5362 - recall_1: 0.6423\n",
      "Epoch 9: val_loss improved from 0.75449 to 0.71301, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.7384 - accuracy: 0.5364 - recall_1: 0.6423 - val_loss: 0.7130 - val_accuracy: 0.5874 - val_recall_1: 0.5448\n",
      "Epoch 10/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.7235 - accuracy: 0.5471 - recall_1: 0.6138\n",
      "Epoch 10: val_loss did not improve from 0.71301\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.7233 - accuracy: 0.5469 - recall_1: 0.6139 - val_loss: 0.7246 - val_accuracy: 0.5163 - val_recall_1: 0.6637\n",
      "Epoch 11/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.7101 - accuracy: 0.5409 - recall_1: 0.6335\n",
      "Epoch 11: val_loss improved from 0.71301 to 0.69648, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.7099 - accuracy: 0.5407 - recall_1: 0.6333 - val_loss: 0.6965 - val_accuracy: 0.5654 - val_recall_1: 0.5822\n",
      "Epoch 12/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.5447 - recall_1: 0.6198\n",
      "Epoch 12: val_loss improved from 0.69648 to 0.68534, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.7002 - accuracy: 0.5448 - recall_1: 0.6196 - val_loss: 0.6853 - val_accuracy: 0.5771 - val_recall_1: 0.5651\n",
      "Epoch 13/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5376 - recall_1: 0.6202\n",
      "Epoch 13: val_loss did not improve from 0.68534\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6939 - accuracy: 0.5376 - recall_1: 0.6202 - val_loss: 0.6941 - val_accuracy: 0.5327 - val_recall_1: 0.6368\n",
      "Epoch 14/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.5457 - recall_1: 0.6224\n",
      "Epoch 14: val_loss did not improve from 0.68534\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6888 - accuracy: 0.5457 - recall_1: 0.6224 - val_loss: 0.6916 - val_accuracy: 0.5297 - val_recall_1: 0.6433\n",
      "Epoch 15/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6868 - accuracy: 0.5381 - recall_1: 0.6208\n",
      "Epoch 15: val_loss improved from 0.68534 to 0.68441, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6868 - accuracy: 0.5382 - recall_1: 0.6204 - val_loss: 0.6844 - val_accuracy: 0.5444 - val_recall_1: 0.6132\n",
      "Epoch 16/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6857 - accuracy: 0.5403 - recall_1: 0.6101\n",
      "Epoch 16: val_loss did not improve from 0.68441\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6857 - accuracy: 0.5403 - recall_1: 0.6097 - val_loss: 0.6879 - val_accuracy: 0.5312 - val_recall_1: 0.6384\n",
      "Epoch 17/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.5303 - recall_1: 0.6233\n",
      "Epoch 17: val_loss improved from 0.68441 to 0.66417, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6846 - accuracy: 0.5303 - recall_1: 0.6228 - val_loss: 0.6642 - val_accuracy: 0.5940 - val_recall_1: 0.5163\n",
      "Epoch 18/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6840 - accuracy: 0.5473 - recall_1: 0.6065\n",
      "Epoch 18: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6839 - accuracy: 0.5472 - recall_1: 0.6067 - val_loss: 0.6997 - val_accuracy: 0.4941 - val_recall_1: 0.6865\n",
      "Epoch 19/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6832 - accuracy: 0.5395 - recall_1: 0.6158\n",
      "Epoch 19: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6831 - accuracy: 0.5394 - recall_1: 0.6163 - val_loss: 0.6843 - val_accuracy: 0.5380 - val_recall_1: 0.6197\n",
      "Epoch 20/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.5433 - recall_1: 0.6206\n",
      "Epoch 20: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6829 - accuracy: 0.5433 - recall_1: 0.6206 - val_loss: 0.6753 - val_accuracy: 0.5648 - val_recall_1: 0.5814\n",
      "Epoch 21/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.5458 - recall_1: 0.6130\n",
      "Epoch 21: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6820 - accuracy: 0.5458 - recall_1: 0.6131 - val_loss: 0.6742 - val_accuracy: 0.5652 - val_recall_1: 0.5782\n",
      "Epoch 22/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.5465 - recall_1: 0.6097\n",
      "Epoch 22: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 13s 16ms/step - loss: 0.6825 - accuracy: 0.5465 - recall_1: 0.6097 - val_loss: 0.6751 - val_accuracy: 0.5637 - val_recall_1: 0.5782\n",
      "Epoch 23/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6829 - accuracy: 0.5437 - recall_1: 0.6194\n",
      "Epoch 23: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 13s 15ms/step - loss: 0.6830 - accuracy: 0.5436 - recall_1: 0.6192 - val_loss: 0.6833 - val_accuracy: 0.5344 - val_recall_1: 0.6262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.5412 - recall_1: 0.6075\n",
      "Epoch 24: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6825 - accuracy: 0.5409 - recall_1: 0.6075 - val_loss: 0.6907 - val_accuracy: 0.5158 - val_recall_1: 0.6621\n",
      "Epoch 25/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5394 - recall_1: 0.6167\n",
      "Epoch 25: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6820 - accuracy: 0.5393 - recall_1: 0.6167 - val_loss: 0.6941 - val_accuracy: 0.5078 - val_recall_1: 0.6678\n",
      "Epoch 26/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6822 - accuracy: 0.5420 - recall_1: 0.6106\n",
      "Epoch 26: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6821 - accuracy: 0.5420 - recall_1: 0.6103 - val_loss: 0.6853 - val_accuracy: 0.5328 - val_recall_1: 0.6327\n",
      "Epoch 27/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6820 - accuracy: 0.5459 - recall_1: 0.6011\n",
      "Epoch 27: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6819 - accuracy: 0.5458 - recall_1: 0.6014 - val_loss: 0.6988 - val_accuracy: 0.4922 - val_recall_1: 0.6906\n",
      "Epoch 28/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.5438 - recall_1: 0.6207\n",
      "Epoch 28: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6812 - accuracy: 0.5438 - recall_1: 0.6208 - val_loss: 0.6895 - val_accuracy: 0.5196 - val_recall_1: 0.6572\n",
      "Epoch 29/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.5483 - recall_1: 0.6079\n",
      "Epoch 29: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6816 - accuracy: 0.5483 - recall_1: 0.6079 - val_loss: 0.7029 - val_accuracy: 0.4842 - val_recall_1: 0.7109\n",
      "Epoch 30/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6801 - accuracy: 0.5479 - recall_1: 0.6159\n",
      "Epoch 30: val_loss did not improve from 0.66417\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6802 - accuracy: 0.5479 - recall_1: 0.6155 - val_loss: 0.6885 - val_accuracy: 0.5216 - val_recall_1: 0.6531\n",
      "Epoch 31/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.5371 - recall_1: 0.6233\n",
      "Epoch 31: val_loss improved from 0.66417 to 0.66276, saving model to /Users/xiaozhangyu/desktop/best_model_hybrid_lstm.h5\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6823 - accuracy: 0.5373 - recall_1: 0.6230 - val_loss: 0.6628 - val_accuracy: 0.5972 - val_recall_1: 0.5383\n",
      "Epoch 32/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6820 - accuracy: 0.5487 - recall_1: 0.5962\n",
      "Epoch 32: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6819 - accuracy: 0.5487 - recall_1: 0.5962 - val_loss: 0.6896 - val_accuracy: 0.5199 - val_recall_1: 0.6580\n",
      "Epoch 33/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.5400 - recall_1: 0.6083\n",
      "Epoch 33: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6818 - accuracy: 0.5400 - recall_1: 0.6073 - val_loss: 0.6676 - val_accuracy: 0.5906 - val_recall_1: 0.5521\n",
      "Epoch 34/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.5589 - recall_1: 0.6022\n",
      "Epoch 34: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6800 - accuracy: 0.5589 - recall_1: 0.6022 - val_loss: 0.7058 - val_accuracy: 0.4757 - val_recall_1: 0.7142\n",
      "Epoch 35/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.5453 - recall_1: 0.6171\n",
      "Epoch 35: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6802 - accuracy: 0.5453 - recall_1: 0.6171 - val_loss: 0.6809 - val_accuracy: 0.5459 - val_recall_1: 0.6116\n",
      "Epoch 36/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5473 - recall_1: 0.6096\n",
      "Epoch 36: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6797 - accuracy: 0.5475 - recall_1: 0.6099 - val_loss: 0.6687 - val_accuracy: 0.5750 - val_recall_1: 0.5676\n",
      "Epoch 37/300\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.5486 - recall_1: 0.6104\n",
      "Epoch 37: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6794 - accuracy: 0.5487 - recall_1: 0.6105 - val_loss: 0.6780 - val_accuracy: 0.5535 - val_recall_1: 0.6116\n",
      "Epoch 38/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.5535 - recall_1: 0.6105\n",
      "Epoch 38: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 13s 15ms/step - loss: 0.6802 - accuracy: 0.5535 - recall_1: 0.6105 - val_loss: 0.7006 - val_accuracy: 0.4866 - val_recall_1: 0.7077\n",
      "Epoch 39/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5457 - recall_1: 0.6206\n",
      "Epoch 39: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6794 - accuracy: 0.5457 - recall_1: 0.6206 - val_loss: 0.6917 - val_accuracy: 0.5119 - val_recall_1: 0.6751\n",
      "Epoch 40/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.5406 - recall_1: 0.6141\n",
      "Epoch 40: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6809 - accuracy: 0.5407 - recall_1: 0.6137 - val_loss: 0.6686 - val_accuracy: 0.5811 - val_recall_1: 0.5562\n",
      "Epoch 41/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.5501 - recall_1: 0.6024\n",
      "Epoch 41: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6803 - accuracy: 0.5501 - recall_1: 0.6024 - val_loss: 0.6897 - val_accuracy: 0.5198 - val_recall_1: 0.6572\n",
      "Epoch 42/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6801 - accuracy: 0.5493 - recall_1: 0.6086\n",
      "Epoch 42: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6802 - accuracy: 0.5495 - recall_1: 0.6079 - val_loss: 0.6706 - val_accuracy: 0.5763 - val_recall_1: 0.5619\n",
      "Epoch 43/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.5511 - recall_1: 0.6085\n",
      "Epoch 43: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6809 - accuracy: 0.5511 - recall_1: 0.6085 - val_loss: 0.6857 - val_accuracy: 0.5336 - val_recall_1: 0.6441\n",
      "Epoch 44/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.5491 - recall_1: 0.6171\n",
      "Epoch 44: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 13s 16ms/step - loss: 0.6792 - accuracy: 0.5492 - recall_1: 0.6167 - val_loss: 0.6687 - val_accuracy: 0.5776 - val_recall_1: 0.5684\n",
      "Epoch 45/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6799 - accuracy: 0.5498 - recall_1: 0.6140\n",
      "Epoch 45: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 13s 15ms/step - loss: 0.6798 - accuracy: 0.5500 - recall_1: 0.6141 - val_loss: 0.6763 - val_accuracy: 0.5543 - val_recall_1: 0.6059\n",
      "Epoch 46/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.5455 - recall_1: 0.6081\n",
      "Epoch 46: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 13s 16ms/step - loss: 0.6809 - accuracy: 0.5455 - recall_1: 0.6081 - val_loss: 0.6924 - val_accuracy: 0.5099 - val_recall_1: 0.6775\n",
      "Epoch 47/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6799 - accuracy: 0.5520 - recall_1: 0.6023\n",
      "Epoch 47: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 13s 15ms/step - loss: 0.6799 - accuracy: 0.5518 - recall_1: 0.6026 - val_loss: 0.6943 - val_accuracy: 0.5046 - val_recall_1: 0.6751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5445 - recall_1: 0.6173\n",
      "Epoch 48: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6794 - accuracy: 0.5445 - recall_1: 0.6173 - val_loss: 0.6636 - val_accuracy: 0.5890 - val_recall_1: 0.5456\n",
      "Epoch 49/300\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.5503 - recall_1: 0.6004\n",
      "Epoch 49: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6809 - accuracy: 0.5502 - recall_1: 0.6004 - val_loss: 0.6890 - val_accuracy: 0.5175 - val_recall_1: 0.6686\n",
      "Epoch 50/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5404 - recall_1: 0.6200\n",
      "Epoch 50: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 14ms/step - loss: 0.6798 - accuracy: 0.5406 - recall_1: 0.6198 - val_loss: 0.6682 - val_accuracy: 0.5738 - val_recall_1: 0.5635\n",
      "Epoch 51/300\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.5447 - recall_1: 0.6110\n",
      "Epoch 51: val_loss did not improve from 0.66276\n",
      "822/822 [==============================] - 12s 15ms/step - loss: 0.6802 - accuracy: 0.5446 - recall_1: 0.6107 - val_loss: 0.6724 - val_accuracy: 0.5642 - val_recall_1: 0.5888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16f156f90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras import regularizers, optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import Recall\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(timesteps, input_dim),\n",
    "               kernel_regularizer=regularizers.l2(0.01),\n",
    "               recurrent_regularizer=regularizers.l2(0.01),\n",
    "               bias_regularizer=regularizers.l2(0.01),\n",
    "               dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', Recall()])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model/best_model_hybrid_lstm.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_split=0.2, callbacks=[early_stopping, checkpoint], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7cb3885",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 1s 4ms/step\n",
      "      Prediction  Actual\n",
      "0       0.470546       0\n",
      "1       0.548851       1\n",
      "2       0.310637       0\n",
      "3       0.559259       0\n",
      "4       0.547991       0\n",
      "...          ...     ...\n",
      "8215    0.483170       0\n",
      "8216    0.415833       0\n",
      "8217    0.538961       0\n",
      "8218    0.477379       1\n",
      "8219    0.416731       0\n",
      "\n",
      "[8220 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the model\n",
    "best_model = load_model('model/best_model_hybrid_lstm.h5')\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Compare the predictions with the actual values\n",
    "comparison = pd.DataFrame({'Prediction': predictions.flatten(), 'Actual': y_test})\n",
    "\n",
    "# Print the comparison\n",
    "print(comparison)\n",
    "predictions_labels = [1 if p > 0.5 else 0 for p in predictions.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dbb7924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_labels)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "043c253f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72      6689\n",
      "           1       0.24      0.53      0.33      1531\n",
      "\n",
      "    accuracy                           0.60      8220\n",
      "   macro avg       0.55      0.57      0.52      8220\n",
      "weighted avg       0.74      0.60      0.64      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions_labels, output_dict=True)\n",
    "print(classification_report(y_test, predictions_labels))\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv('result/hybrid_lstm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
